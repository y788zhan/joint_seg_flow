{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "import datetime\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import argparse\n",
    "import json\n",
    "import socket\n",
    "from PIL import Image\n",
    "from util import *\n",
    "import numpy as np\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from copy import deepcopy\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import image as mpimg\n",
    "from matplotlib.colors import hsv_to_rgb\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "logPath = \"training/\"\n",
    "snapshotPath = \"snapshots/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open(\"hyperParams.json\") as f:\n",
    "    instanceParams = json.load(f)\n",
    "\n",
    "instanceParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printFrequency = instanceParams[\"printFreq\"]\n",
    "batchSize = instanceParams[\"batchSize\"]\n",
    "\n",
    "iterations = instanceParams[\"iterations\"]\n",
    "baseLearningRate = instanceParams[\"baseLR\"]\n",
    "learningRate = baseLearningRate\n",
    "snapshotFrequency = instanceParams[\"snapshotFreq\"]\n",
    "\n",
    "from dotmap import DotMap\n",
    "arg = DotMap()\n",
    "arg.logDev = False\n",
    "arg.resume = 'y'\n",
    "resume, startIteration, snapshotFiles = checkResume(snapshotPath,logPath, arg)\n",
    "iterations = 1000 * 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device(\"/gpu:0\"):\n",
    "    trainingData = TrainingData(batchSize,instanceParams)\n",
    "\n",
    "with tf.device(\"/gpu:0\"):\n",
    "    # init\n",
    "    with tf.variable_scope(\"netShare\"):\n",
    "        networkBodyF = NetworkBody(trainingData,instanceParams)\n",
    "    with tf.variable_scope(\"netShare\",reuse=True):\n",
    "        networkBodyB = NetworkBody(trainingData,instanceParams,flipInput=True)\n",
    "\n",
    "    trainingLoss = TrainingLoss(instanceParams,networkBodyF,networkBodyB,trainingData)\n",
    "    solver,learningRateTensor = attachSolver(trainingLoss.loss)\n",
    "\n",
    "    # loss scheduling\n",
    "    recLossBWeightTensor = trainingLoss.recLossBWeight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge summaries\n",
    "merged = tf.summary.merge_all()\n",
    "# saver\n",
    "saver = tf.train.Saver(max_to_keep=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printFrequency = 36\n",
    "snapshotFrequency = 2000\n",
    "iterations = 10000\n",
    "print(printFrequency)\n",
    "print(snapshotFrequency)\n",
    "print(iterations)\n",
    "startIteration = 500000\n",
    "print(startIteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# start\n",
    "with sessionSetup(arg) as sess:\n",
    "#     if resume:\n",
    "#         saver.restore(sess,snapshotPath+snapshotFiles[-1][:-6])\n",
    "#     else:\n",
    "#         sess.run(tf.initialize_all_variables())\n",
    "    saver.restore(sess,\n",
    "                  '../model_download_scripts/photometric_smoothness/weights/iter_0000000000500000.ckpt')\n",
    "\n",
    "    trainingData.dataQueuer.start_queueing(sess)\n",
    "\n",
    "    #start summary writer\n",
    "    summary_writer = tf.summary.FileWriter(logPath, sess.graph)\n",
    "\n",
    "    #run\n",
    "    lastPrint = time.time()\n",
    "    for i in range(startIteration, startIteration + iterations + 10):\n",
    "        # scheduled values\n",
    "        learningRate = learningRateSchedule(baseLearningRate, i)\n",
    "        recLossBWeight = unsupLossBSchedule(i)\n",
    "\n",
    "         #run training\n",
    "        feed_dict = {\n",
    "            learningRateTensor: learningRate,\n",
    "            recLossBWeightTensor: recLossBWeight,\n",
    "        }\n",
    "        summary,result,totalLoss = sess.run([merged,solver,trainingLoss.loss], feed_dict=feed_dict)\n",
    "\n",
    "        if (i+1) % printFrequency == 0:\n",
    "            timeDiff = time.time() - lastPrint\n",
    "            itPerSec = printFrequency/timeDiff\n",
    "            remainingIt = startIteration + iterations + 10 - i\n",
    "            eta = remainingIt/itPerSec\n",
    "            print(\"Iteration \"+str(i+1)+\": loss: \"+str(totalLoss)+\", iterations per second: \"+str(itPerSec)+\", ETA: \"+str(datetime.timedelta(seconds=eta)))+\", lr: \"+str(learningRate)\n",
    "\n",
    "            summary_writer.add_summary(summary,i+1)\n",
    "            summary_writer.flush()\n",
    "            lastPrint = time.time()\n",
    "\n",
    "        if (i+1) % snapshotFrequency == 0:\n",
    "            saver.save(sess,\"snapshots/iter_\"+str(i+1).zfill(16)+\".ckpt\")\n",
    "\n",
    "        sys.stdout.flush()\n",
    "\n",
    "    #close queing\n",
    "    trainingData.dataQueuer.close(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetRoot = '../example_data/'\n",
    "frame0Path = '../example_data/datalists/hockey_im0.txt'\n",
    "frame1Path = '../example_data/datalists/hockey_im1.txt'\n",
    "gt0Path = '../example_data/datalists/hockey_gt0.txt'\n",
    "desiredHeight = 480\n",
    "desiredWidth = 854"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(frame0Path) as f:\n",
    "    imagePairs0 = [datasetRoot+x[:-1] for x in f.readlines()]\n",
    "with open(frame1Path) as f:\n",
    "    imagePairs1 = [datasetRoot+x[:-1] for x in f.readlines()]\n",
    "with open(gt0Path) as f:\n",
    "    gtPairs1 = [datasetRoot+x[:-1] for x in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testData = TestData(imagePairs0,imagePairs1,gtPairs1,1,desiredHeight,desiredWidth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device(\"/gpu:0\"):\n",
    "    with tf.variable_scope(\"netShare\"):\n",
    "        networkBody = NetworkBody(testData,instanceParams)\n",
    "    flowFinal = networkBody.flows[0]\n",
    "    gt = testData.frame0[\"gt\"]\n",
    "    sLoss = asymmetricSmoothLoss(flowFinal, gt, instanceParams, 1, 1, None, instanceParams[\"boundaryAlpha\"], True)\n",
    "    sGrad = tf.gradients(sLoss, flowFinal)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flowViz = flowToRgb(flowFinal)\n",
    "transformGrid = flowTransformGrid(flowFinal)\n",
    "mean = tf.expand_dims(tf.expand_dims(tf.expand_dims([0.407871, 0.457525, 0.481094], 0), 0), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()\n",
    "\n",
    "# config tensorflow\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "config.allow_soft_placement = True\n",
    "iterations = 510000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_length = 70\n",
    "start = 0\n",
    "\n",
    "flows = []\n",
    "viz = []\n",
    "gradients = []\n",
    "ground_truths = []\n",
    "with tf.Session(config=config) as sess:\n",
    "    saver.restore(sess,\"snapshots/iter_\"+str(iterations).zfill(16)+\".ckpt\")\n",
    "\n",
    "    # run\n",
    "    lastPrint = time.time()\n",
    "    for i in range(start, start + test_length):\n",
    "        feed_dict = {\n",
    "            testData.im0File: imagePairs0[i],\n",
    "            testData.im1File: imagePairs1[i],\n",
    "            testData.gt0File: gtPairs1[i]\n",
    "        }\n",
    "        hsv, f, g, t = sess.run([flowViz, flowFinal, sGrad, gt],feed_dict=feed_dict)\n",
    "\n",
    "        gradients.append(deepcopy(g))\n",
    "        ground_truths.append(deepcopy(t))\n",
    "        flows.append(deepcopy(f))\n",
    "        h, w = 480, 854\n",
    "        arr = np.maximum(np.minimum(np.asarray(hsv),1), 0)\n",
    "        arr = np.squeeze(np.asarray(arr*255,np.uint8))\n",
    "        im = Image.fromarray(arr[:h,:w,:])\n",
    "        viz.append(deepcopy(im))\n",
    "        # im.save(\"{}/{}.png\".format(result_dir, str(i).zfill(3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_smooth_grad(i, overlay=True, sparsity=32):\n",
    "    # optical flow hsv\n",
    "    plt.figure(frameon=False, figsize=(15,10))\n",
    "    plt.imshow(viz[i])\n",
    "\n",
    "    # segmentation mask\n",
    "    if overlay:\n",
    "        plt.imshow(np.reshape(ground_truths[i][0], (480, 854)), cmap='gray', alpha=0.1)\n",
    "\n",
    "    # optical flow vector field\n",
    "    X, Y = np.mgrid[0:854, 0:480]\n",
    "    est = flows[i][0]\n",
    "    est = np.transpose(est, (1, 0, 2))\n",
    "    U, V = est[:,:,0], est[:,:,1]\n",
    "    plt.quiver(X[::sparsity, ::sparsity],\n",
    "               Y[::sparsity, ::sparsity],\n",
    "               U[::sparsity, ::sparsity],\n",
    "               V[::sparsity, ::sparsity],\n",
    "               color='black',\n",
    "               edgecolor='k', alpha=0.8)\n",
    "\n",
    "    # gradient vector field\n",
    "    sgrad = np.transpose(gradients[0][0], (1, 0, 2))\n",
    "    U, V = sgrad[:,:,0], sgrad[:,:,1]\n",
    "    plt.quiver(X[::sparsity, ::sparsity],\n",
    "               Y[::sparsity, ::sparsity],\n",
    "               U[::sparsity, ::sparsity],\n",
    "               V[::sparsity, ::sparsity],\n",
    "               color='yellow',\n",
    "               edgecolor='k', alpha=0.8)\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_smooth_grad(8, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
