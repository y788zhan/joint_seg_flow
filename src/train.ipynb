{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "import datetime\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import argparse\n",
    "import json\n",
    "import socket\n",
    "from PIL import Image\n",
    "from util import *\n",
    "import numpy as np\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib notebook\n",
    "from copy import deepcopy\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import image as mpimg\n",
    "from matplotlib.colors import hsv_to_rgb\n",
    "from helpers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "logPath = \"training/\"\n",
    "snapshotPath = \"snapshots/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'baseLR': 1e-05,\n",
       " u'batchSize': 2,\n",
       " u'borderThicknessH': 0.02,\n",
       " u'borderThicknessW': 0.02,\n",
       " u'boundaryAlpha': 6.5,\n",
       " u'dataset': u'kitti2012',\n",
       " u'flowScale': 20.0,\n",
       " u'gradParams': {u'robustness': 0.46, u'scale': 255.0, u'weight': 6.408},\n",
       " u'instanceName': u'unsupFlownet',\n",
       " u'iterations': 500000,\n",
       " u'lossComponents': {u'asymmetricSmooth': True,\n",
       "  u'backward': False,\n",
       "  u'boundaries': False,\n",
       "  u'gradient': False,\n",
       "  u'smooth2nd': False},\n",
       " u'photoParams': {u'robustness': 0.53, u'scale': 360.0},\n",
       " u'printFreq': 1000,\n",
       " u'resnet': False,\n",
       " u'smooth2ndParams': {u'robustness': 0.21, u'scale': 1.0, u'weight': 0.53},\n",
       " u'smoothOccParams': {u'robustness': 0.9, u'scale': 1.8},\n",
       " u'smoothParams': {u'robustness': 0.99, u'scale': 3.5, u'weight': 0.025},\n",
       " u'snapFreq': 5000,\n",
       " u'snapshotFreq': 20000,\n",
       " u'weightDecay': 0.0}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"hyperParams.json\") as f:\n",
    "    instanceParams = json.load(f)\n",
    "\n",
    "instanceParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resuming from iteration 520000\n"
     ]
    }
   ],
   "source": [
    "printFrequency = instanceParams[\"printFreq\"]\n",
    "batchSize = instanceParams[\"batchSize\"]\n",
    "\n",
    "iterations = instanceParams[\"iterations\"]\n",
    "baseLearningRate = instanceParams[\"baseLR\"]\n",
    "learningRate = baseLearningRate\n",
    "snapshotFrequency = instanceParams[\"snapshotFreq\"]\n",
    "\n",
    "from dotmap import DotMap\n",
    "arg = DotMap()\n",
    "arg.logDev = False\n",
    "arg.resume = 'y'\n",
    "resume, startIteration, snapshotFiles = checkResume(snapshotPath,logPath, arg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading Tensor(\"ImagePairData/image_data_reader/Placeholder:0\", dtype=string, device=/device:GPU:0)\n",
      "Reading Tensor(\"ImagePairData/image_data_reader_1/Placeholder:0\", dtype=string, device=/device:GPU:0)\n",
      "Reading Tensor(\"ImagePairData/image_data_reader_2/Placeholder:0\", dtype=string, device=/device:GPU:0)\n",
      "Reading Tensor(\"ImagePairData/image_data_reader_3/Placeholder:0\", dtype=string, device=/device:GPU:0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From components/rgbToGray.py:10: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "> /home/y788zhang/joint_seg_flow/src/util/TrainingData.py(87)__init__()\n",
      "-> self.frame0 = {\n",
      "(Pdb) type(imData0aug)\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "(Pdb) imData0aug.shape\n",
      "TensorShape([Dimension(2), Dimension(480), Dimension(854), Dimension(3)])\n",
      "(Pdb) borderMask.shape\n",
      "TensorShape([Dimension(1), Dimension(480), Dimension(854), Dimension(1)])\n"
     ]
    }
   ],
   "source": [
    "with tf.device(\"/gpu:0\"):\n",
    "    trainingData = TrainingData(batchSize,instanceParams)\n",
    "\n",
    "with tf.device(\"/gpu:0\"):\n",
    "    # init\n",
    "    with tf.variable_scope(\"netShare\"):\n",
    "        networkBodyF = NetworkBody(trainingData,instanceParams)\n",
    "    with tf.variable_scope(\"netShare\",reuse=True):\n",
    "        networkBodyB = NetworkBody(trainingData,instanceParams,flipInput=True)\n",
    "\n",
    "    trainingLoss = TrainingLoss(instanceParams,networkBodyF,networkBodyB,trainingData)\n",
    "    solver,learningRateTensor = attachSolver(trainingLoss.loss)\n",
    "\n",
    "    # loss scheduling\n",
    "    recLossBWeightTensor = trainingLoss.recLossBWeight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge summaries\n",
    "merged = tf.summary.merge_all()\n",
    "# saver\n",
    "saver = tf.train.Saver(max_to_keep=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printFrequency = 100\n",
    "snapshotFrequency = 5000\n",
    "iterations = 100000\n",
    "startIteration = 520000\n",
    "print(printFrequency)\n",
    "print(snapshotFrequency)\n",
    "print(iterations)\n",
    "print(startIteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# start\n",
    "with sessionSetup(arg) as sess:\n",
    "    if resume:\n",
    "        saver.restore(sess,snapshotPath+snapshotFiles[-1][:-6])\n",
    "\n",
    "#     saver.restore(sess,\n",
    "#                   '../model_download_scripts/photometric_smoothness/weights/iter_0000000000500000.ckpt')\n",
    "\n",
    "    trainingData.dataQueuer.start_queueing(sess)\n",
    "\n",
    "    #start summary writer\n",
    "    summary_writer = tf.summary.FileWriter(logPath, sess.graph)\n",
    "\n",
    "    #run\n",
    "    lastPrint = time.time()\n",
    "    for i in range(startIteration, startIteration + iterations + 10):\n",
    "        # scheduled values\n",
    "        learningRate = learningRateSchedule(baseLearningRate, i)\n",
    "        recLossBWeight = unsupLossBSchedule(i)\n",
    "\n",
    "         #run training\n",
    "        feed_dict = {\n",
    "            learningRateTensor: learningRate,\n",
    "            recLossBWeightTensor: recLossBWeight,\n",
    "        }\n",
    "        summary,result,totalLoss = sess.run([merged,solver,trainingLoss.loss], feed_dict=feed_dict)\n",
    "\n",
    "        if (i+1) % printFrequency == 0:\n",
    "            timeDiff = time.time() - lastPrint\n",
    "            itPerSec = printFrequency/timeDiff\n",
    "            remainingIt = startIteration + iterations + 10 - i\n",
    "            eta = remainingIt/itPerSec\n",
    "            print(\"Iteration \"+str(i+1)+\": loss: \"+str(totalLoss)+\", iterations per second: \"+str(itPerSec)+\", ETA: \"+str(datetime.timedelta(seconds=eta)))+\", lr: \"+str(learningRate)\n",
    "\n",
    "            summary_writer.add_summary(summary,i+1)\n",
    "            summary_writer.flush()\n",
    "            lastPrint = time.time()\n",
    "\n",
    "        if (i+1) % snapshotFrequency == 0:\n",
    "            saver.save(sess,\"snapshots/iter_\"+str(i+1).zfill(16)+\".ckpt\")\n",
    "\n",
    "        sys.stdout.flush()\n",
    "\n",
    "    #close queing\n",
    "    trainingData.dataQueuer.close(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetRoot = '../example_data/'\n",
    "frame0Path = '../example_data/datalists/swing_11_im0.txt'\n",
    "frame1Path = '../example_data/datalists/swing_11_im1.txt'\n",
    "gt0Path = '../example_data/datalists/swing_11_gt0.txt'\n",
    "desiredHeight = 480\n",
    "desiredWidth = 854"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(frame0Path) as f:\n",
    "    imagePairs0 = [datasetRoot+x[:-1] for x in f.readlines()]\n",
    "with open(frame1Path) as f:\n",
    "    imagePairs1 = [datasetRoot+x[:-1] for x in f.readlines()]\n",
    "with open(gt0Path) as f:\n",
    "    gtPairs1 = [datasetRoot+x[:-1] for x in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testData = TestData(imagePairs0,imagePairs1,gtPairs1,1,desiredHeight,desiredWidth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device(\"/gpu:0\"):\n",
    "    with tf.variable_scope(\"netShare\"):\n",
    "        networkBody = NetworkBody(testData,instanceParams)\n",
    "    flowFinal = networkBody.flows[0]\n",
    "    gt = testData.frame0[\"gt\"]\n",
    "    sLoss = asymmetricSmoothLoss(flowFinal, gt, instanceParams, 1, 1, None, instanceParams[\"boundaryAlpha\"], True)\n",
    "    sGrad = tf.gradients(sLoss, flowFinal)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flowViz = flowToRgb(flowFinal)\n",
    "transformGrid = flowTransformGrid(flowFinal)\n",
    "mean = tf.expand_dims(tf.expand_dims(tf.expand_dims([0.407871, 0.457525, 0.481094], 0), 0), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()\n",
    "\n",
    "# config tensorflow\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "config.allow_soft_placement = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_length = 70\n",
    "start = 0\n",
    "result_dir = 'results'\n",
    "iterations = 520000\n",
    "\n",
    "flows = []\n",
    "viz = []\n",
    "gradients = []\n",
    "ground_truths = []\n",
    "arrs = []\n",
    "with tf.Session(config=config) as sess:\n",
    "    saver.restore(sess,\"snapshots/iter_\"+str(iterations).zfill(16)+\".ckpt\")\n",
    "\n",
    "    # run\n",
    "    lastPrint = time.time()\n",
    "    for i in range(start, start + min(test_length, len(imagePairs0))):\n",
    "        feed_dict = {\n",
    "            testData.im0File: imagePairs0[i],\n",
    "            testData.im1File: imagePairs1[i],\n",
    "            testData.gt0File: gtPairs1[i]\n",
    "        }\n",
    "        hsv, f, g, t = sess.run([flowViz, flowFinal, sGrad, gt],feed_dict=feed_dict)\n",
    "\n",
    "        gradients.append(deepcopy(g))\n",
    "        ground_truths.append(deepcopy(t))\n",
    "        flows.append(deepcopy(f))\n",
    "        h, w = 480, 854\n",
    "        arr = np.maximum(np.minimum(np.asarray(hsv),1), 0)\n",
    "        arr = np.squeeze(np.asarray(arr*255,np.uint8))\n",
    "        arrs.append(deepcopy(arr[:h,:w,:]))\n",
    "        im = Image.fromarray(arr[:h,:w,:])\n",
    "        viz.append(deepcopy(im))\n",
    "        # im.save(\"{}/{}.png\".format(result_dir, str(i).zfill(3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flows = np.array(flows)\n",
    "gradients = np.array(gradients)\n",
    "arrs = np.array(arrs)\n",
    "ground_truths = np.array(ground_truths)\n",
    "\n",
    "flows = np.squeeze(flows, axis=1)\n",
    "gradients = np.squeeze(gradients, axis=1)\n",
    "ground_truths = np.squeeze(ground_truths, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(arrs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flows[0][400,470]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flows[0][400,471]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.abs(4.2757964 - 4.580006)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save(\"./NPY/flow_w1_g25\", flows)\n",
    "# np.save(\"./NPY/gradient_w1_g25\", gradients)\n",
    "# np.save(\"./NPY/arrs_w1\", arrs)\n",
    "# np.save(\"./NPY/gt\", ground_truths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_smooth_grad(i, overlay=True, sparsity=32):\n",
    "    # optical flow hsv\n",
    "    # plt.figure(figsize=(15,9))\n",
    "    plt.imshow(viz[i])\n",
    "\n",
    "    # segmentation mask\n",
    "    if overlay:\n",
    "        plt.imshow(np.reshape(ground_truths[i], (480, 854)), cmap='gray', alpha=0.1)\n",
    "\n",
    "    # optical flow vector field\n",
    "    X, Y = np.mgrid[0:854, 0:480]\n",
    "    est = flows[i]\n",
    "    est = np.transpose(est, (1, 0, 2))\n",
    "    U, V = est[:,:,0], est[:,:,1]\n",
    "    plt.quiver(X[::sparsity, ::sparsity],\n",
    "               Y[::sparsity, ::sparsity],\n",
    "               U[::sparsity, ::sparsity],\n",
    "               V[::sparsity, ::sparsity],\n",
    "               color='black',\n",
    "               edgecolor='k', alpha=0.8,angles='xy',scale_units='xy', scale=1)\n",
    "\n",
    "    # gradient vector field\n",
    "    sgrad = -np.transpose(gradients[0], (1, 0, 2))\n",
    "    U, V = sgrad[:,:,0], sgrad[:,:,1]\n",
    "    plt.quiver(X[::sparsity, ::sparsity],\n",
    "               Y[::sparsity, ::sparsity],\n",
    "               U[::sparsity, ::sparsity],\n",
    "               V[::sparsity, ::sparsity],\n",
    "               color='yellow',\n",
    "               edgecolor='k', alpha=0.8,angles='xy',scale_units='xy', scale=300)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_smooth_grad(11, True, sparsity=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
